{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tiktoken\n",
    "from pathlib import Path\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "from src.model import MODEL_ARCHITECTURES, GPTModel\n",
    "from src.token import token_ids_to_text, text_to_token_ids\n",
    "from src.train import (\n",
    "    train_model_simple,\n",
    ")\n",
    "from src.generate import generate\n",
    "from src.loader import create_dataloader_v1\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_configs = MODEL_ARCHITECTURES['gpt2-small']\n",
    "custom_configs = {\n",
    "    \"vocab_size\": 50257,  # Vocabulary size\n",
    "    \"context_length\": 256,  # Context length\n",
    "    \"drop_rate\": 0.1,  # Dropout rate\n",
    "    \"qkv_bias\": False,  # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = base_configs | custom_configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = Path('data/the-verdict.txt')\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=model_configs['context_length'],\n",
    "    stride=model_configs['context_length'],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=model_configs['context_length'],\n",
    "    stride=model_configs['context_length'],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cafe/.envs/gpt_from_scratch/lib/python3.10/site-packages/setuptools/version.py:1: UserWarning: Module src was already imported from None, but /home/cafe/gpt_from_scrath is being added to sys.path\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (Step 000005): Train loss 8.545, Val loss 8.634\n",
      "Every effor moves you,,,,,,,,,,,,,.                                    \n",
      "Epoch 2 (Step 000010): Train loss 6.959, Val loss 7.227\n",
      "Epoch 2 (Step 000015): Train loss 6.055, Val loss 6.620\n",
      "Every effor moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and the, and, and, and, and, and, and, and, and, and, and,\n",
      "Epoch 3 (Step 000020): Train loss 16.093, Val loss 16.200\n",
      "Epoch 3 (Step 000025): Train loss 5.365, Val loss 6.402\n",
      "Every effor moves you.              \", I had, and I had, and I had. I had the of the of the of the of the of the of the of the, and, and I\n",
      "Epoch 4 (Step 000030): Train loss 5.121, Val loss 6.439\n",
      "Epoch 4 (Step 000035): Train loss 4.575, Val loss 6.280\n",
      "Every effor moves you know\"I that he was--I was his I was his last and I was his I was his pictures, and I was his of the picture--as of the picture. \"I was the picture and I was his I was his I\n",
      "Epoch 5 (Step 000040): Train loss 4.313, Val loss 6.190\n",
      "Epoch 5 (Step 000045): Train loss 3.503, Val loss 6.129\n",
      "Every effor moves you know, and in the picture--I--I had been his last I had been--his, with a, I had been to me--I had the fact, I had been the fact, I had been--I, I was his pictures\n",
      "Epoch 6 (Step 000050): Train loss 3.092, Val loss 6.161\n",
      "Every effor moves you know, and in the picture--I had the fact with a little a.             \"--as Jack himself at my elbow and he had a little a--because he had a little to\n",
      "Epoch 7 (Step 000055): Train loss 2.718, Val loss 6.178\n",
      "Epoch 7 (Step 000060): Train loss 2.460, Val loss 6.133\n",
      "Every effor moves you know, and in the picture for nothing--I told Mrs.                                     \n",
      "Epoch 8 (Step 000065): Train loss 1.668, Val loss 6.205\n",
      "Epoch 8 (Step 000070): Train loss 1.322, Val loss 6.285\n",
      "Every effor moves you know, and in spite of, the deep arm-chairs forward. \"There: make yourself comfortable--and here are the cigars you like.\"                     \n",
      "Epoch 9 (Step 000075): Train loss 0.945, Val loss 6.267\n",
      "Epoch 9 (Step 000080): Train loss 0.661, Val loss 6.326\n",
      "Every effor moves you know; and in spite of, his pictures--so handsome, so charming, so disarming, and went on groping and muddling; then I looked at the donkey again. I saw that, my eye fell on a small picture above\n",
      "Epoch 10 (Step 000085): Train loss 0.445, Val loss 6.402\n",
      "Epoch 10 (Step 000090): Train loss 0.366, Val loss 6.426\n",
      "Every effor moves you'd never touched a brush.\"   I told Mrs. Stroud so when she began to stammer something about her poverty. I remember getting off a prodigious phrase about the sketch of the donkey. \"There were days when I couldn\n"
     ]
    }
   ],
   "source": [
    "model = GPTModel(model_configs)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=4e-4, weight_decay=0.1)\n",
    "num_epochs = 10\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs=num_epochs,\n",
    "    eval_freq=5,\n",
    "    eval_iter=5,\n",
    "    start_context=\"Every effor moves you\",\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f5000dcba30>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ids = text_to_token_ids(\"Every effort moves you\", tokenizer).to(device)\n",
    "\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_ids,\n",
    "    max_new_tokens=15,\n",
    "    context_size=model_configs['context_length'],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you as his pictures with random rather a cheap genius-- that seen a _.\n"
     ]
    }
   ],
   "source": [
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt_from_scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
