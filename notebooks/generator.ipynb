{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tiktoken\n",
    "from pathlib import Path\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "from gepeto.model import MODEL_ARCHITECTURES, GPTModel\n",
    "from gepeto.token import token_ids_to_text, text_to_token_ids\n",
    "from gepeto.train import (\n",
    "    train_model_simple,\n",
    ")\n",
    "from gepeto.generate import generate\n",
    "from gepeto.loader import create_dataloader_v1\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model Architecture from OpenAI's GPT2-Small\n",
    "\n",
    "base_configs = MODEL_ARCHITECTURES['gpt2-small']\n",
    "\n",
    "custom_configs = {\n",
    "    \"vocab_size\": 50257,  # Vocabulary size\n",
    "    \"context_length\": 256,  # The context size of our model will be diminshed due to hardware constraints\n",
    "    \"drop_rate\": 0.1,  # Dropout rate\n",
    "    \"qkv_bias\": False,  # Query-Key-Value bias\n",
    "}\n",
    "\n",
    "model_configs = base_configs | custom_configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path('../data/the-verdict.txt')\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20480\n",
      "Tokens: 5146\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=model_configs['context_length'],\n",
    "    stride=model_configs['context_length'],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=model_configs['context_length'],\n",
    "    stride=model_configs['context_length'],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (Step 000000): Train loss 9.794, Val loss 9.909\n",
      "Epoch 1 (Step 000005): Train loss 8.038, Val loss 8.324\n",
      "Every effor moves you,,,,,,,,,,,,,.                                    \n",
      "Epoch 2 (Step 000010): Train loss 6.598, Val loss 7.041\n",
      "Epoch 2 (Step 000015): Train loss 5.996, Val loss 6.574\n",
      "Every effor moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and\n",
      "Epoch 3 (Step 000020): Train loss 5.555, Val loss 6.443\n",
      "Epoch 3 (Step 000025): Train loss 6.114, Val loss 7.800\n",
      "Every effor moves you.                                                 \n",
      "Epoch 4 (Step 000030): Train loss 4.264, Val loss 6.266\n",
      "Epoch 4 (Step 000035): Train loss 4.176, Val loss 6.193\n",
      "Every effor moves you.      \"--I had been.            \"I had been, and I had been, and he had been, and I had been the, I had been.\n",
      "Epoch 5 (Step 000040): Train loss 3.386, Val loss 6.173\n",
      "Every effor moves you know, and in a little of the end, I had been. \"Oh, I was, in fact, had been to me.      \"Oh, I had a little a little the room, I had been\n",
      "Epoch 6 (Step 000045): Train loss 3.153, Val loss 6.254\n",
      "Epoch 6 (Step 000050): Train loss 2.597, Val loss 6.228\n",
      "Every effor moves you know, and in a, in a--I had a good-century so that he was a--and here are the Riv, in the moment--as Jack himself, as he had the his painting, and down the room, I had been\n",
      "Epoch 7 (Step 000055): Train loss 2.436, Val loss 6.259\n",
      "Epoch 7 (Step 000060): Train loss 1.665, Val loss 6.186\n",
      "Every effor moves you know, and in spite of, his pictures--so handsome, so--so it was no great surprise to me to have to see a smile behind his pictures.  \"Oh, I saw that he was \"There were days when I couldn\n",
      "Epoch 8 (Step 000065): Train loss 1.258, Val loss 6.252\n",
      "Epoch 8 (Step 000070): Train loss 1.005, Val loss 6.348\n",
      "Every effor moves you know.\"   I glanced after him, and uncertain.  \"Once, when I looked up, I seemed to see a smile behind his close grayish beard--as if he had the donkey. \"There were days when I couldn\n",
      "Epoch 9 (Step 000075): Train loss 0.720, Val loss 6.322\n",
      "Epoch 9 (Step 000080): Train loss 0.504, Val loss 6.402\n",
      "Every effor moves you know.\"   I glanced after him, struck by his last word. Victor Grindle was, in fact, becoming the man of the moment--as Jack himself, one might put it, had been the man of the hour. The younger\n",
      "Epoch 10 (Step 000085): Train loss 0.343, Val loss 6.474\n",
      "Every effor moves you'd never touched a brush.\"      \"I turned back to my work, and went on groping and muddling; then I looked at the donkey again. I saw that, when Stroud laid in the first stroke\n"
     ]
    }
   ],
   "source": [
    "model = GPTModel(model_configs)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=4e-4, weight_decay=0.1)\n",
    "num_epochs = 10\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs=num_epochs,\n",
    "    eval_freq=5,\n",
    "    eval_iter=5,\n",
    "    start_context=\"Every effor moves you\",\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f5eb6788db0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ids = text_to_token_ids(\"Every effort moves you\", tokenizer).to(device)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_ids,\n",
    "    max_new_tokens=15,\n",
    "    context_size=model_configs['context_length'],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you as Hermia to do the picture for a smile that seen a curious of\n"
     ]
    }
   ],
   "source": [
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt_from_scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
